{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: TfTransform # \n",
    "\n",
    "**Learning Objectives**\n",
    "1. Preproccess data and engineer new features using TfTransform \n",
    "1. Create and deploy Apache Beam pipeline \n",
    "1. Use processed data to train taxifare model locally then serve a prediction\n",
    "\n",
    "## Introduction \n",
    "While Pandas is fine for experimenting, for operationalization of your workflow it is better to do preprocessing in Apache Beam. This will also help if you need to preprocess data in flight, since Apache Beam allows for streaming. In this lab we will pull data from BigQuery then use Apache Beam  TfTransform to process the data.  \n",
    "\n",
    "Only specific combinations of TensorFlow/Beam are supported by tf.transform so make sure to get a combo that works. In this lab we will be using: \n",
    "* TFT 0.15.0\n",
    "* TF 2.0 \n",
    "* Apache Beam [GCP] 2.16.0\n",
    "\n",
    "NOTE: In the output of the next cell you may ignore any WARNINGS or ERRORS related to the following:  \"witwidget-gpu\", \"fairing\", \"pbr, \"hdfscli\", \"hdfscli-avro\", \"fastavro\", \"plasma_store\", and/or \"gen_client\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chown: invalid user: ‘jupyter:jupyter’\n"
     ]
    }
   ],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/BigData/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /root/.local/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (2.1.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.33.6)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.13.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.17.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.31.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.16.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.25.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (41.4.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/anaconda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.9.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/anaconda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.23)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /root/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/anaconda/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: apache-beam[gcp]==2.16.0 in /root/.local/lib/python3.7/site-packages (2.16.0)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (2.0.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.5.0.post1 in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (3.13.0)\n",
      "Requirement already satisfied: oauth2client<4,>=2.0.1 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (3.0.0)\n",
      "Requirement already satisfied: avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.10.1)\n",
      "Requirement already satisfied: pyyaml<4.0.0,>=3.12 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (3.13)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (3.11.2)\n",
      "Requirement already satisfied: future<1.0.0,>=0.16.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.17.1)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.7)\n",
      "Requirement already satisfied: dill<0.3.1,>=0.3.0 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.3.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (2019.3)\n",
      "Requirement already satisfied: grpcio<2,>=1.12.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.31.0)\n",
      "Requirement already satisfied: fastavro<0.22,>=0.21.4 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.21.24)\n",
      "Requirement already satisfied: pyarrow<0.15.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.14.1)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.4.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (2.5.8)\n",
      "Requirement already satisfied: httplib2<=0.12.0,>=0.8 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.12.0)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1; extra == \"gcp\" in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.4.3)\n",
      "Requirement already satisfied: google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.0.2)\n",
      "Requirement already satisfied: google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.0.0)\n",
      "Requirement already satisfied: cachetools<4,>=3.1.0; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (3.1.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.17.1)\n",
      "Requirement already satisfied: google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.7.4)\n",
      "Requirement already satisfied: google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.5.28)\n",
      "Requirement already satisfied: pbr>=0.11 in /root/.local/lib/python3.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.16.0) (5.5.1)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/anaconda/lib/python3.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.16.0) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/anaconda/lib/python3.7/site-packages (from protobuf<4,>=3.5.0.post1->apache-beam[gcp]==2.16.0) (41.4.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/anaconda/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.16.0) (4.6)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/anaconda/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.16.0) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.16.0) (0.2.8)\n",
      "Requirement already satisfied: numpy>=1.14 in /opt/conda/anaconda/lib/python3.7/site-packages (from pyarrow<0.15.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\"->apache-beam[gcp]==2.16.0) (1.17.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/anaconda/lib/python3.7/site-packages (from pydot<2,>=1.2.0->apache-beam[gcp]==2.16.0) (2.4.2)\n",
      "Requirement already satisfied: docopt in /root/.local/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (0.6.2)\n",
      "Requirement already satisfied: requests>=2.7.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (2.25.0)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.19.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-core<2,>=0.28.1; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (1.23.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (0.12.3)\n",
      "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /root/.local/lib/python3.7/site-packages (from google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (0.4.1)\n",
      "Requirement already satisfied: fasteners>=0.14 in /root/.local/lib/python3.7/site-packages (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (0.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (2019.9.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (1.24.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.19.0->google-cloud-core<2,>=0.28.1; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (1.52.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.19.0->google-cloud-core<2,>=0.28.1; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (1.23.0)\n",
      "Requirement already satisfied: monotonic>=0.1 in /root/.local/lib/python3.7/site-packages (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (1.5)\n",
      "Requirement already satisfied: tensorflow-transform==0.15.0 in /root/.local/lib/python3.7/site-packages (0.15.0)\n",
      "Requirement already satisfied: tfx-bsl<0.16,>=0.15 in /root/.local/lib/python3.7/site-packages (from tensorflow-transform==0.15.0) (0.15.3)\n",
      "Requirement already satisfied: protobuf<4,>=3.7 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow-transform==0.15.0) (3.13.0)\n",
      "Requirement already satisfied: tensorflow<2.2,>=1.15 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow-transform==0.15.0) (2.1.0)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.16 in /root/.local/lib/python3.7/site-packages (from tensorflow-transform==0.15.0) (2.16.0)\n",
      "Requirement already satisfied: absl-py<0.9,>=0.7 in /root/.local/lib/python3.7/site-packages (from tensorflow-transform==0.15.0) (0.8.1)\n",
      "Requirement already satisfied: six<2,>=1.10 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow-transform==0.15.0) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-metadata<0.16,>=0.15 in /root/.local/lib/python3.7/site-packages (from tensorflow-transform==0.15.0) (0.15.2)\n",
      "Requirement already satisfied: pydot<2,>=1.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow-transform==0.15.0) (1.4.1)\n",
      "Requirement already satisfied: numpy<2,>=1.16 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow-transform==0.15.0) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-serving-api<3,>=1.15 in /root/.local/lib/python3.7/site-packages (from tfx-bsl<0.16,>=0.15->tensorflow-transform==0.15.0) (2.3.0)\n",
      "Requirement already satisfied: pyarrow<0.15.0,>=0.14.0 in /root/.local/lib/python3.7/site-packages (from tfx-bsl<0.16,>=0.15->tensorflow-transform==0.15.0) (0.14.1)\n",
      "Requirement already satisfied: psutil<6,>=5.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from tfx-bsl<0.16,>=0.15->tensorflow-transform==0.15.0) (5.6.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/anaconda/lib/python3.7/site-packages (from protobuf<4,>=3.7->tensorflow-transform==0.15.0) (41.4.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (0.2.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (3.3.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (0.33.6)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (1.11.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (2.1.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (1.31.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (2.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (1.0.8)\n",
      "Requirement already satisfied: fastavro<0.22,>=0.21.4 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.21.24)\n",
      "Requirement already satisfied: avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (1.10.1)\n",
      "Requirement already satisfied: dill<0.3.1,>=0.3.0 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.3.0)\n",
      "Requirement already satisfied: future<1.0.0,>=0.16.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.17.1)\n",
      "Requirement already satisfied: httplib2<=0.12.0,>=0.8 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.12.0)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (3.11.2)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (1.7)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (2.0.0)\n",
      "Requirement already satisfied: oauth2client<4,>=2.0.1 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (3.0.0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (2019.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (2.5.8)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (2.8.0)\n",
      "Requirement already satisfied: pyyaml<4.0.0,>=3.12 in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (3.13)\n",
      "Requirement already satisfied: cachetools<4,>=3.1.0; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (3.1.1)\n",
      "Requirement already satisfied: google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (1.0.2)\n",
      "Requirement already satisfied: google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.5.28)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1; extra == \"gcp\" in /opt/conda/anaconda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (1.4.3)\n",
      "Requirement already satisfied: google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (1.17.1)\n",
      "Requirement already satisfied: google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (1.0.0)\n",
      "Requirement already satisfied: google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\" in /root/.local/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (1.7.4)\n",
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorflow-metadata<0.16,>=0.15->tensorflow-transform==0.15.0) (1.52.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/anaconda/lib/python3.7/site-packages (from pydot<2,>=1.2->tensorflow-transform==0.15.0) (2.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (3.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (0.4.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (1.23.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (2.25.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/anaconda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (2.9.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /root/.local/lib/python3.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/anaconda/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (4.6)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/anaconda/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.4.8)\n",
      "Requirement already satisfied: docopt in /root/.local/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.6.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.12.3)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (1.23.0)\n",
      "Requirement already satisfied: fasteners>=0.14 in /root/.local/lib/python3.7/site-packages (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.15)\n",
      "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /root/.local/lib/python3.7/site-packages (from google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/anaconda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (0.23)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (1.24.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (2.8)\n",
      "Requirement already satisfied: monotonic>=0.1 in /root/.local/lib/python3.7/site-packages (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.16->tensorflow-transform==0.15.0) (1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (3.1.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/anaconda/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow-transform==0.15.0) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user apache-beam[gcp]==2.16.0 \n",
    "!pip install --user tensorflow-transform==0.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download .whl file for tensorflow-transform. We will pass this file to Beam Pipeline Options so it is installed on the DataFlow workers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-transform==0.15.0\n",
      "  File was already downloaded /tensorflow-transform-0.15.0.tar.gz\n",
      "Successfully downloaded tensorflow-transform\n"
     ]
    }
   ],
   "source": [
    "!pip download tensorflow-transform==0.15.0 --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Restart the kernel</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow==2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Ensure the right version of Tensorflow is installed.\n",
    "!pip freeze | grep tensorflow==2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apache-beam==2.16.0\n",
      "tensorflow==2.1.0\n",
      "tensorflow-estimator==2.1.0\n",
      "tensorflow-metadata==0.15.2\n",
      "tensorflow-serving-api==2.3.0\n",
      "tensorflow-transform==0.15.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze | grep -e 'flow\\|beam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to those of your environment to try this notebook out\n",
    "\n",
    "BUCKET = 'saberbf0098'\n",
    "PROJECT = \"saberbf-2020\"  # Replace with your PROJECT\n",
    "REGION = \"us-east1\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input source: BigQuery\n",
    "\n",
    "Get data from BigQuery but defer the majority of filtering etc. to Beam.\n",
    "Note that the dayofweek column is now strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "    \"\"\"Creates a query with the proper splits.\n",
    "\n",
    "    Args:\n",
    "        phase: int, 1=train, 2=valid.\n",
    "        EVERY_N: int, take an example EVERY_N rows.\n",
    "\n",
    "    Returns:\n",
    "        Query string with the proper splits.\n",
    "    \"\"\"\n",
    "    base_query = \"\"\"\n",
    "    WITH daynames AS\n",
    "    (SELECT ['Sun', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat'] AS daysofweek)\n",
    "    SELECT\n",
    "    (tolls_amount + fare_amount) AS fare_amount,\n",
    "    daysofweek[ORDINAL(EXTRACT(DAYOFWEEK FROM pickup_datetime))] AS dayofweek,\n",
    "    EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "    pickup_longitude AS pickuplon,\n",
    "    pickup_latitude AS pickuplat,\n",
    "    dropoff_longitude AS dropofflon,\n",
    "    dropoff_latitude AS dropofflat,\n",
    "    passenger_count AS passengers,\n",
    "    'notneeded' AS key\n",
    "    FROM\n",
    "    `nyc-tlc.yellow.trips`, daynames\n",
    "    WHERE\n",
    "    trip_distance > 0 AND fare_amount > 0\n",
    "    \"\"\"\n",
    "    if EVERY_N is None:\n",
    "        if phase < 2:\n",
    "            # training\n",
    "            query = \"\"\"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST\n",
    "            (pickup_datetime AS STRING), 4)) < 2\"\"\".format(base_query)\n",
    "        else:\n",
    "            query = \"\"\"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(\n",
    "            pickup_datetime AS STRING), 4)) = {1}\"\"\".format(base_query, phase)\n",
    "    else:\n",
    "        query = \"\"\"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(\n",
    "        pickup_datetime AS STRING)), {1})) = {2}\"\"\".format(\n",
    "            base_query, EVERY_N, phase)\n",
    "\n",
    "    return query\n",
    "\n",
    "query = create_query(2, 100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull this query down into a Pandas DataFrame and take a look at some of the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.8</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.789790</td>\n",
       "      <td>40.647172</td>\n",
       "      <td>-73.977878</td>\n",
       "      <td>40.766360</td>\n",
       "      <td>2</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.1</td>\n",
       "      <td>Thurs</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.976694</td>\n",
       "      <td>40.752008</td>\n",
       "      <td>-73.863868</td>\n",
       "      <td>40.853071</td>\n",
       "      <td>1</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.993298</td>\n",
       "      <td>40.730806</td>\n",
       "      <td>-73.966804</td>\n",
       "      <td>40.803945</td>\n",
       "      <td>1</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.5</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.986655</td>\n",
       "      <td>40.743667</td>\n",
       "      <td>-73.998180</td>\n",
       "      <td>40.732015</td>\n",
       "      <td>1</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.985027</td>\n",
       "      <td>40.758720</td>\n",
       "      <td>-73.994760</td>\n",
       "      <td>40.743637</td>\n",
       "      <td>2</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount dayofweek  hourofday  pickuplon  pickuplat  dropofflon  \\\n",
       "0         49.8       Fri          0 -73.789790  40.647172  -73.977878   \n",
       "1         30.1     Thurs          0 -73.976694  40.752008  -73.863868   \n",
       "2         24.0       Mon          0 -73.993298  40.730806  -73.966804   \n",
       "3          6.5       Sun          0 -73.986655  40.743667  -73.998180   \n",
       "4          5.0       Mon          0 -73.985027  40.758720  -73.994760   \n",
       "\n",
       "   dropofflat  passengers        key  \n",
       "0   40.766360           2  notneeded  \n",
       "1   40.853071           1  notneeded  \n",
       "2   40.803945           1  notneeded  \n",
       "3   40.732015           1  notneeded  \n",
       "4   40.743637           2  notneeded  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.242599</td>\n",
       "      <td>13.244075</td>\n",
       "      <td>-72.576852</td>\n",
       "      <td>39.973146</td>\n",
       "      <td>-72.748974</td>\n",
       "      <td>40.006091</td>\n",
       "      <td>1.722118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.447462</td>\n",
       "      <td>6.548354</td>\n",
       "      <td>10.133452</td>\n",
       "      <td>5.777329</td>\n",
       "      <td>12.981577</td>\n",
       "      <td>5.664887</td>\n",
       "      <td>1.351062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-78.133333</td>\n",
       "      <td>-73.991278</td>\n",
       "      <td>-751.400000</td>\n",
       "      <td>-73.977970</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-73.991849</td>\n",
       "      <td>40.734954</td>\n",
       "      <td>-73.991236</td>\n",
       "      <td>40.734008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-73.981824</td>\n",
       "      <td>40.752640</td>\n",
       "      <td>-73.980164</td>\n",
       "      <td>40.753427</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-73.967418</td>\n",
       "      <td>40.766700</td>\n",
       "      <td>-73.964153</td>\n",
       "      <td>40.767832</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>143.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>40.806487</td>\n",
       "      <td>41.366138</td>\n",
       "      <td>40.785400</td>\n",
       "      <td>41.366138</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount     hourofday     pickuplon     pickuplat    dropofflon  \\\n",
       "count  11181.000000  11181.000000  11181.000000  11181.000000  11181.000000   \n",
       "mean      11.242599     13.244075    -72.576852     39.973146    -72.748974   \n",
       "std        9.447462      6.548354     10.133452      5.777329     12.981577   \n",
       "min        2.500000      0.000000    -78.133333    -73.991278   -751.400000   \n",
       "25%        6.000000      9.000000    -73.991849     40.734954    -73.991236   \n",
       "50%        8.500000     14.000000    -73.981824     40.752640    -73.980164   \n",
       "75%       12.500000     19.000000    -73.967418     40.766700    -73.964153   \n",
       "max      143.000000     23.000000     40.806487     41.366138     40.785400   \n",
       "\n",
       "         dropofflat    passengers  \n",
       "count  11181.000000  11181.000000  \n",
       "mean      40.006091      1.722118  \n",
       "std        5.664887      1.351062  \n",
       "min      -73.977970      0.000000  \n",
       "25%       40.734008      1.000000  \n",
       "50%       40.753427      1.000000  \n",
       "75%       40.767832      2.000000  \n",
       "max       41.366138      6.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = bigquery.Client().query(query).to_dataframe()\n",
    "display(df_valid.head())\n",
    "df_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = './trained_model'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True)\n",
    "tf.compat.v1.summary.FileWriterCache.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ML dataset using tf.transform and Dataflow\n",
    "\n",
    "Let's use Cloud Dataflow to read in the BigQuery data and write it out as TFRecord files. Along the way, let's use tf.transform to do scaling and transforming. Using tf.transform allows us to save the metadata to ensure that the appropriate transformations get carried out during prediction as well.\n",
    "\n",
    "NOTE:  You may ignore any WARNING related to \"tensorflow\" in the output after executing the code cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transformed_data` is type `pcollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching local job ... hang on\n",
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dayofweek': <tf.Tensor 'inputs/inputs/dayofweek_copy:0' shape=(None,) dtype=string>, 'dropofflat': <tf.Tensor 'inputs/inputs/dropofflat_copy:0' shape=(None,) dtype=float32>, 'dropofflon': <tf.Tensor 'inputs/inputs/dropofflon_copy:0' shape=(None,) dtype=float32>, 'fare_amount': <tf.Tensor 'inputs/inputs/F_fare_amount_copy:0' shape=(None,) dtype=float32>, 'hourofday': <tf.Tensor 'inputs/inputs/hourofday_copy:0' shape=(None,) dtype=int64>, 'key': <tf.Tensor 'inputs/inputs/key_copy:0' shape=(None,) dtype=string>, 'passengers': <tf.Tensor 'inputs/inputs/passengers_copy:0' shape=(None,) dtype=int64>, 'pickuplat': <tf.Tensor 'inputs/inputs/pickuplat_copy:0' shape=(None,) dtype=float32>, 'pickuplon': <tf.Tensor 'inputs/inputs/pickuplon_copy:0' shape=(None,) dtype=float32>}\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/5bdde27c48d440aebf997d96c37588c4/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/5bdde27c48d440aebf997d96c37588c4/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/e74ffdad91074a278a923542d4c470ef/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/e74ffdad91074a278a923542d4c470ef/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "WARNING:root:Dataset saberbf-2020:temp_dataset_3295be7ac4f8499896ff2210bc110b3f does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Dataset saberbf-2020:temp_dataset_a9516deed678488caf4af717873c1da7 does not exist so we will create it as temporary with location=US\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./preproc_tft/tmp/tftransform_tmp/74ce033fbb284d0e94222ae24c5c7c45/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./preproc_tft/tmp/tftransform_tmp/74ce033fbb284d0e94222ae24c5c7c45/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/74ce033fbb284d0e94222ae24c5c7c45/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/74ce033fbb284d0e94222ae24c5c7c45/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\t\\n\\007Const:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\t\\n\\007Const:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\t\\n\\007Const:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\t\\n\\007Const:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\t\\n\\007Const:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\t\\n\\007Const:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_metadata as tfmd\n",
    "from tensorflow_transform.beam import impl as beam_impl\n",
    "\n",
    "\n",
    "def is_valid(inputs):\n",
    "    \"\"\"Check to make sure the inputs are valid.\n",
    "\n",
    "    Args:\n",
    "        inputs: dict, dictionary of TableRow data from BigQuery.\n",
    "\n",
    "    Returns:\n",
    "        True if the inputs are valid and False if they are not.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pickup_longitude = inputs['pickuplon']\n",
    "        dropoff_longitude = inputs['dropofflon']\n",
    "        pickup_latitude = inputs['pickuplat']\n",
    "        dropoff_latitude = inputs['dropofflat']\n",
    "        hourofday = inputs['hourofday']\n",
    "        dayofweek = inputs['dayofweek']\n",
    "        passenger_count = inputs['passengers']\n",
    "        fare_amount = inputs['fare_amount']\n",
    "        return fare_amount >= 2.5 and pickup_longitude > -78 \\\n",
    "            and pickup_longitude < -70 and dropoff_longitude > -78 \\\n",
    "            and dropoff_longitude < -70 and pickup_latitude > 37 \\\n",
    "            and pickup_latitude < 45 and dropoff_latitude > 37 \\\n",
    "            and dropoff_latitude < 45 and passenger_count > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def preprocess_tft(inputs):\n",
    "    \"\"\"Preproccess the features and add engineered features with tf transform.\n",
    "\n",
    "    Args:\n",
    "        dict, dictionary of TableRow data from BigQuery.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of preprocessed data after scaling and feature engineering.\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    print(inputs)\n",
    "    result = {}\n",
    "    result['fare_amount'] = tf.identity(inputs['fare_amount'])\n",
    "    # build a vocabulary\n",
    "    result['dayofweek'] = tft.string_to_int(inputs['dayofweek'])\n",
    "    result['hourofday'] = tf.identity(inputs['hourofday'])  # pass through\n",
    "    # scaling numeric values\n",
    "    result['pickuplon'] = (tft.scale_to_0_1(inputs['pickuplon']))\n",
    "    result['pickuplat'] = (tft.scale_to_0_1(inputs['pickuplat']))\n",
    "    result['dropofflon'] = (tft.scale_to_0_1(inputs['dropofflon']))\n",
    "    result['dropofflat'] = (tft.scale_to_0_1(inputs['dropofflat']))\n",
    "    result['passengers'] = tf.cast(inputs['passengers'], tf.float32)  # a cast\n",
    "    # arbitrary TF func\n",
    "    result['key'] = tf.as_string(tf.ones_like(inputs['passengers']))\n",
    "    # engineered features\n",
    "    latdiff = inputs['pickuplat'] - inputs['dropofflat']\n",
    "    londiff = inputs['pickuplon'] - inputs['dropofflon']\n",
    "    result['latdiff'] = tft.scale_to_0_1(latdiff)\n",
    "    result['londiff'] = tft.scale_to_0_1(londiff)\n",
    "    dist = tf.sqrt(latdiff * latdiff + londiff * londiff)\n",
    "    result['euclidean'] = tft.scale_to_0_1(dist)\n",
    "    return result\n",
    "\n",
    "\n",
    "def preprocess(in_test_mode):\n",
    "    \"\"\"Sets up preprocess pipeline.\n",
    "\n",
    "    Args:\n",
    "        in_test_mode: bool, False to launch DataFlow job, True to run locally.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import os.path\n",
    "    import tempfile\n",
    "    from apache_beam.io import tfrecordio\n",
    "    from tensorflow_transform.coders import example_proto_coder\n",
    "    from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "    from tensorflow_transform.tf_metadata import dataset_schema\n",
    "    from tensorflow_transform.beam import tft_beam_io\n",
    "    from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "\n",
    "    job_name = 'preprocess-taxi-features' + '-'\n",
    "    job_name += datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    if in_test_mode:\n",
    "        import shutil\n",
    "        print('Launching local job ... hang on')\n",
    "        OUTPUT_DIR = './preproc_tft'\n",
    "        shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "        EVERY_N = 100000\n",
    "    else:\n",
    "        print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "        OUTPUT_DIR = 'gs://{0}/taxifare/preproc_tft/'.format(BUCKET)\n",
    "        import subprocess\n",
    "        subprocess.call('gsutil rm -r {}'.format(OUTPUT_DIR).split())\n",
    "        EVERY_N = 10000\n",
    "\n",
    "    options = {\n",
    "        'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "        'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'num_workers': 1,\n",
    "        'max_num_workers': 1,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True,\n",
    "        'direct_num_workers': 1,\n",
    "        'extra_packages': ['tensorflow-transform-0.15.0.tar.gz']\n",
    "        }\n",
    "\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    if in_test_mode:\n",
    "        RUNNER = 'DirectRunner'\n",
    "    else:\n",
    "        RUNNER = 'DataflowRunner'\n",
    "\n",
    "    # Set up raw data metadata\n",
    "    raw_data_schema = {\n",
    "        colname: dataset_schema.ColumnSchema(\n",
    "            tf.string, [], dataset_schema.FixedColumnRepresentation())\n",
    "        for colname in 'dayofweek,key'.split(',')\n",
    "    }\n",
    "\n",
    "    raw_data_schema.update({\n",
    "        colname: dataset_schema.ColumnSchema(\n",
    "            tf.float32, [], dataset_schema.FixedColumnRepresentation())\n",
    "        for colname in\n",
    "        'fare_amount,pickuplon,pickuplat,dropofflon,dropofflat'.split(',')\n",
    "    })\n",
    "\n",
    "    raw_data_schema.update({\n",
    "        colname: dataset_schema.ColumnSchema(\n",
    "            tf.int64, [], dataset_schema.FixedColumnRepresentation())\n",
    "        for colname in 'hourofday,passengers'.split(',')\n",
    "    })\n",
    "\n",
    "    raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
    "        dataset_schema.Schema(raw_data_schema))\n",
    "\n",
    "    # Run Beam\n",
    "    with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "        with beam_impl.Context(temp_dir=os.path.join(OUTPUT_DIR, 'tmp')):\n",
    "            # Save the raw data metadata\n",
    "            (raw_data_metadata |\n",
    "                'WriteInputMetadata' >> tft_beam_io.WriteMetadata(\n",
    "                    os.path.join(\n",
    "                        OUTPUT_DIR, 'metadata/rawdata_metadata'), pipeline=p))\n",
    "\n",
    "            # Read training data from bigquery and filter rows\n",
    "            raw_data = (p | 'train_read' >> beam.io.Read(\n",
    "                    beam.io.BigQuerySource(\n",
    "                        query=create_query(1, EVERY_N),\n",
    "                        use_standard_sql=True)) |\n",
    "                        'train_filter' >> beam.Filter(is_valid))\n",
    "\n",
    "            raw_dataset = (raw_data, raw_data_metadata)\n",
    "\n",
    "            # Analyze and transform training data\n",
    "            transformed_dataset, transform_fn = (\n",
    "                raw_dataset | beam_impl.AnalyzeAndTransformDataset(\n",
    "                    preprocess_tft))\n",
    "            transformed_data, transformed_metadata = transformed_dataset\n",
    "\n",
    "            # Save transformed train data to disk in efficient tfrecord format\n",
    "            transformed_data | 'WriteTrainData' >> tfrecordio.WriteToTFRecord(\n",
    "                os.path.join(OUTPUT_DIR, 'train'), file_name_suffix='.gz',\n",
    "                coder=example_proto_coder.ExampleProtoCoder(\n",
    "                    transformed_metadata.schema))\n",
    "\n",
    "            # Read eval data from bigquery and filter rows\n",
    "            raw_test_data = (p | 'eval_read' >> beam.io.Read(\n",
    "                beam.io.BigQuerySource(\n",
    "                    query=create_query(2, EVERY_N),\n",
    "                    use_standard_sql=True)) | 'eval_filter' >> beam.Filter(\n",
    "                        is_valid))\n",
    "\n",
    "            raw_test_dataset = (raw_test_data, raw_data_metadata)\n",
    "\n",
    "            # Transform eval data\n",
    "            transformed_test_dataset = (\n",
    "                (raw_test_dataset, transform_fn) | beam_impl.TransformDataset()\n",
    "                )\n",
    "            transformed_test_data, _ = transformed_test_dataset\n",
    "\n",
    "            # Save transformed train data to disk in efficient tfrecord format\n",
    "            (transformed_test_data |\n",
    "                'WriteTestData' >> tfrecordio.WriteToTFRecord(\n",
    "                    os.path.join(OUTPUT_DIR, 'eval'), file_name_suffix='.gz',\n",
    "                    coder=example_proto_coder.ExampleProtoCoder(\n",
    "                        transformed_metadata.schema)))\n",
    "\n",
    "            # Save transformation function to disk for use at serving time\n",
    "            (transform_fn |\n",
    "                'WriteTransformFn' >> transform_fn_io.WriteTransformFn(\n",
    "                    os.path.join(OUTPUT_DIR, 'metadata')))\n",
    "\n",
    "# Change to True to run locally\n",
    "preprocess(in_test_mode=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take __10-15 minutes__. You cannot go on in this lab until your DataFlow job has succesfully completed. \n",
    "\n",
    "You may monitor the progress of the Dataflow job in the GCP console on the Dataflow page.\n",
    "\n",
    "When you see the Jupyter notebook status has returned to \"Idle\" you may proceed to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://saberbf0098/taxifare/preproc_tft/\n",
      "gs://saberbf0098/taxifare/preproc_tft/tmp/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# ls preproc_tft\n",
    "gsutil ls gs://${BUCKET}/taxifare/preproc_tft/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train off preprocessed data ##\n",
    "Now that we have our data ready and verified it is in the correct location we can train our taxifare model locally.\n",
    "\n",
    "NOTE:  You may ignore any WARNING related to \"tensorflow\" in any of the outputs that follow from this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/bin/python3: Error while finding module specification for 'task.py' (ModuleNotFoundError: No module named 'task')\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'#rm -r ./taxi_trained\\nexport PYTHONPATH=${PYTHONPATH}:$PWD\\npython3 -m task.py \\\\\\n    --train_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/train*\" \\\\\\n    --eval_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/eval*\"  \\\\\\n    --output_dir=./taxi_trained \\\\\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-93ee875ed6fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#rm -r ./taxi_trained\\nexport PYTHONPATH=${PYTHONPATH}:$PWD\\npython3 -m task.py \\\\\\n    --train_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/train*\" \\\\\\n    --eval_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/eval*\"  \\\\\\n    --output_dir=./taxi_trained \\\\\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</opt/conda/anaconda/lib/python3.7/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'#rm -r ./taxi_trained\\nexport PYTHONPATH=${PYTHONPATH}:$PWD\\npython3 -m task.py \\\\\\n    --train_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/train*\" \\\\\\n    --eval_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/eval*\"  \\\\\\n    --output_dir=./taxi_trained \\\\\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#rm -r ./taxi_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:$PWD\n",
    "python3 -m task.py \\\n",
    "    --train_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/train*\" \\\n",
    "    --eval_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/eval*\"  \\\n",
    "    --output_dir=./taxi_trained \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:  If you get any directory not found error then you may need to rerun the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '//taxi_trained/export/exporter': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls $PWD/taxi_trained/export/exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create fake data in JSON format and use it to serve a prediction with gcloud ai-platform local predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/test.json\n",
    "{\"dayofweek\":0, \"hourofday\":17, \"pickuplon\": -73.885262, \"pickuplat\": 40.773008, \"dropofflon\": -73.987232, \"dropofflat\": 40.732403, \"passengers\": 2.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo find \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine\" -name '*.pyc' -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "model_dir=$(ls $PWD/taxi_trained/export/exporter/)\n",
    "gcloud ai-platform local predict \\\n",
    "    --model-dir=./taxi_trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=/tmp/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
